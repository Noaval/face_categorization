---
title: "Main Analysis"
author: "Noa Valansi"
date: last-modified
title-block-banner: "#525266"
execute: 
  warning: false
  message: false
  cache: false
format:
  html:
    embed-resources: true
    toc: true
    toc-depth: 3
editor: visual
bibliography: references.bib
---

# Analysis plan

For both DV's (reaction time and answers) the plan will be similar:\
      1. Gradually fitting models with minimum random effects (random intercept per participant). Checking what fixed effects adding significant explained variance.\
      2. Gradually fitting models with more random effects (random slopes for Ethnicity, identity and interaction, and Nameal title). Checking what is the least complex model fitting to the data (the model containing the last random effect that added significant amount of explained variance).\
      3. Simple slopes analysis.\
      4. Exploratory analysis regarding target's gender (3-way interaction).

# Maximal model structure

Model selection will be done gradually. This is the maximum structure:

## Reaction time

I will check several options for modelling reaction time (Inverse Gaussian, Log-Normal and Normal), this is the Inverse Gaussian model. The Reaction time of participant $i$ in trial $j$ is:

$$
RT_{ij} \sim IG(\mu_i,\lambda)
$$

Where:

Level 1:

$$
\mu_i=\beta_{0i}+\beta_{1i} \cdot identityDifferent+\beta_{2i} \cdot socialstatusARAB+\beta_{3i} \cdot identityDifferent\cdot socialstatusARAB
$$

Level 2:

$$
  \begin{bmatrix}
        \beta_0 \cr
        \beta_1 \cr
        \beta_2 \cr
        \beta_3
  \end{bmatrix} \sim MVN(\begin{bmatrix}
                        \gamma_{00} \cr
                        \gamma_{10} \cr
                        \gamma_{20} \cr
                        \gamma_{30}
                       \end{bmatrix},\begin{pmatrix}
                                      \tau_0^2 & \tau_0\tau_1 \rho_{01} & \tau_0\tau_2 \rho_{02} & \tau_0\tau_3 \rho_{03} \cr
                                      \tau_1\tau_0 \rho_{01} & \tau_1^2 & \tau_1\tau_2 \rho_{12} & \tau_1\tau_3 \rho_{13} \cr
                                      \tau_2\tau_0 \rho_{02} & \tau_2\tau_1 \rho_{12} & \tau_2^2 & \tau_2\tau_3 \rho_{23} \cr
                                      \tau_3\tau_0 \rho_{03} & \tau_3\tau_1 \rho_{13} & \tau_3\tau_2 \rho_{23} & \tau_3^2
                                     \end{pmatrix})
$$

$$
\beta_{0i}=\gamma_{00}+\tau_{0i}
$$

$$
\beta_{1i}=\gamma_{10}+\tau_{1i}
$$

$$
\beta_{2i}=\gamma_{20}+\tau_{2i}
$$

$$
\beta_{3i}=\gamma_{30}+\tau_{3i}
$$

And $[\rho_{01}, \rho_{02}, \rho_{03}, \rho_{12}, \rho_{13}, \rho_{23}]$ are the correlation coefficients between random effects.

## Identity Responses

Responses for identity questions will be modeled with a mixed effects binomial model with the probit link function. The probability of participant $i$ to answer "*Different*" in each trial is:

$$
P(response=Different)=\phi(\theta_i-\mu_i)
$$

$\phi$ is the standard normal CDF.

Where:

Level 1:

$\theta_i$ is the criterion (general tendency to answer "Different") of participant $i$.

$$
\theta_i=\gamma_{00}+\tau_{0i}
$$

$$
\mu_i=\beta_{1i} \cdot identityDifferent+\beta_{2i} \cdot socialstatusARAB+\beta_{3i} \cdot identityDifferent\cdot socialstatusARAB
$$

Level 2:

$$
  \begin{bmatrix}
        \theta \cr
        \beta_1 \cr
        \beta_2 \cr
        \beta_3
  \end{bmatrix} \sim N(\begin{bmatrix}
                        \gamma_{00} \cr
                        \gamma_{10} \cr
                        \gamma_{20} \cr
                        \gamma_{30}
                       \end{bmatrix},\begin{pmatrix}
                                      \tau_0^2 & \tau_0\tau_1 \rho_{01} & \tau_0\tau_2 \rho_{02} & \tau_0\tau_3 \rho_{03} \cr
                                      \tau_1\tau_0 \rho_{01} & \tau_1^2 & \tau_1\tau_2 \rho_{12} & \tau_1\tau_3 \rho_{13} \cr
                                      \tau_2\tau_0 \rho_{02} & \tau_2\tau_1 \rho_{12} & \tau_2^2 & \tau_2\tau_3 \rho_{23} \cr
                                      \tau_3\tau_0 \rho_{03} & \tau_3\tau_1 \rho_{13} & \tau_3\tau_2 \rho_{23} & \tau_3^2
                                     \end{pmatrix})
$$

$$
\beta_{1i}=\gamma_{10}+\tau_{1i}
$$

$$
\beta_{2i}=\gamma_{20}+\tau_{2i}
$$

$$
\beta_{3i}=\gamma_{30}+\tau_{3i}
$$

And $[\rho_{01}, \rho_{02}, \rho_{03}, \rho_{12}, \rho_{13}, \rho_{23}]$ are the correlation coefficients between the random effects.

# Setup

```{r}
#| output: false
library(tidyverse)
library(patchwork)
library(flextable)
library(lmerTest)
library(optimx)
library(performance)
library(parameters)
library(bayestestR)
library(emmeans)
library(ggeffects)
library(ggdist)


```

# Loading data

```{r}
data <- read_rds("C:/Users/97252/Documents/GitHub/face_cater/Study 1/data/preprocessed_data.rds")
```

#### Colors for plots

```{r}
color_vec <- c("#4b3d8f", "#37a987")
```

# Reaction time

## Tidying

```{r}


data_clean <- data |>
  mutate(Name = factor(Name),
         Ethnicity = factor(Ethnicity, levels = c("JEWISH", "ARAB")),
         identity = factor(Identity, levels = c("Same", "Diff")),
         target_sex = factor(target_sex, levels = c("male", "female")),
         id = factor(Participant_Private_ID)) |>  # Corrected this line
  mutate(Ethnicity_e = case_when(Ethnicity == "ARAB" ~ 1,
                                 Ethnicity == "JEWISH" ~ -1),  ## for factor effect coding
         identity_e = case_when(identity == "Diff" ~ 1,
                                identity == "Same" ~ -1),
         target_sex_e = case_when(target_sex == "male" ~ 1,
                                  target_sex == "female" ~ -1)) |>
  group_by(id) |>
  mutate(trial = row_number(id)) |>
  ungroup() |>
  filter(Correct_Identity == "yes")
```

## Looking at the data

```{r}
#| code-fold: true
#| code-summary: "ggplot code"
rt_descriptives_plot <- ggplot(data_clean, aes(x = Reaction_time, y = Identity, fill = Ethnicity, color = Ethnicity)) +
  stat_slab(alpha = 0.7) +
  geom_point(alpha = 0.5, position = position_jitter(width = 0.7, height = 0), show.legend = F) +
  theme_classic() +
  labs(y = "Face repetition condition", x = "Reaction Time (ms)", fill = "Ethnicity") +
  guides(color = "none") +
  scale_x_continuous(breaks = seq(200, 900, 50), labels = seq(200, 900, 50)) +
  scale_fill_manual(values = color_vec) +
  scale_color_manual(values = scales::muted(color_vec)) +
  labs(title = "Reaction times",
       subtitle = "RT look smaller for 'Same' condition, not visible interaction with social status") +
  theme(axis.title = element_text(size = 12, family = "serif"),
        plot.title = element_text(size = 20, family = "serif", hjust = 0.5),
        plot.subtitle = element_text(size = 13, family = "serif", hjust = 0.5))

rt_descriptives_plot
```

```{r}
#| echo: false
#| eval: false
ggsave(filename = "rt_descriptive_dist_plot.png", plot = rt_descriptives_plot, path = "../plots/", width = 2450, height = 2100, units = "px")
```

## Per-participant reaction time

```{r}
#| code-fold: true
#| code-summary: "ggplot code"
per_p_rt <- data_clean |>
  group_by(id) |>
  mutate(pm_rt = mean(Reaction_time, na.rm = T)) |>
  ungroup() |>
  ggplot(aes(x = Participant_Private_ID, y = pm_rt)) +
  geom_point(aes(x = Participant_Private_ID, y = Reaction_time)) +
  geom_point(color = "red", size = 2.5)

per_p_rt
```

## Conditional means

```{r}
cond_means <- data_clean |>
  group_by(Ethnicity, identity) |>
  reframe(mean = mean(Reaction_time),
          sd = sd(Reaction_time))

flextable(cond_means)
```

## Model choice

Checking three possible models and figuring which will be better: 1. Inverse Gaussian with the identity link function 2. Gaussian with the log link function 3. Gaussian with the identity link function ("regular" OLS linear regression)

### Gaussian

```{r}

library(Matrix) 
library(lme4)


model0_rt_gaussian <- lmer(Reaction_time ~ 1 + (1 | id),
                           data = data_clean)

model_parameters(model0_rt_gaussian)

icc(model0_rt_gaussian)
```

```{r}
plot(posterior_predictive_check(model0_rt_gaussian))
```

```{r}
model1_rt_gaussian <- lmer(Reaction_time ~ Ethnicity_e + identity_e + (1 | id),
                           data = data_clean)

model_parameters(model1_rt_gaussian)
```

```{r}
plot(posterior_predictive_check(model1_rt_gaussian))
```

```{r}
model2_rt_gaussian <- lmer(Reaction_time ~ Ethnicity_e * identity_e + (1 | id),
                           data = data_clean)

model_parameters(model2_rt_gaussian)
```

```{r}
plot(posterior_predictive_check(model2_rt_gaussian))
```

```{r}
anova(model0_rt_gaussian, model1_rt_gaussian)
```

```{r}
anova(model1_rt_gaussian, model2_rt_gaussian)
```

### Log-Gaussian

```{r}
model0_rt_log <- lmer(log(Reaction_time) ~ 1 + (1 | id),
                      data = data_clean)

model_parameters(model0_rt_log, exponentiate = T)

icc(model0_rt_log)
```

```{r}
plot(posterior_predictive_check(model0_rt_log))
```

Regression coefficients should be interpreted as ratios - e.g. if $\beta_{identity}=1.2$ mean RT in "different" conditions is 1.2 **times** greater then mean RT in "same" condition.

```{r}
model1_rt_log <- lmer(log(Reaction_time) ~ Ethnicity_e + identity_e + (1 | id),
                      data = data_clean)

model_parameters(model1_rt_log, exponentiate = T)
```

```{r}
plot(posterior_predictive_check(model1_rt_log))
```

```{r}
model2_rt_log <- lmer(log(Reaction_time) ~ Ethnicity_e * identity_e + (1 | id),
                      data = data_clean)

model_parameters(model2_rt_log, exponentiate = T)
```

```{r}
plot(posterior_predictive_check(model2_rt_log))
```

```{r}
anova(model0_rt_log, model1_rt_log)
```

```{r}
anova(model1_rt_log, model2_rt_log)
```

### Inverse Gaussian

```{r}
model0_rt_invGauss <- glmer(Reaction_time ~ 1 + (1 | id),
                            data = data_clean,
                            family = inverse.gaussian(link = "identity"))

model_parameters(model0_rt_invGauss)

icc(model0_rt_invGauss)
```

```{r}
#| echo: false
#| eval: false
write_rds(model0_rt_invGauss, file = "../models/model0_rt_invGauss.rds")
```

```{r}
#| echo: false
model0_rt_invGauss <- read_rds("../models/model0_rt_invGauss.rds")
```

```{r}
plot(posterior_predictive_check(model0_rt_invGauss))
```

```{r}
model1_rt_invGauss <- glmer(Reaction_time ~ Ethnicity_e + identity_e + (1 | id),
                            data = data_clean,
                            family = inverse.gaussian(link = "identity"))

model_parameters(model1_rt_invGauss)
```

```{r}
#| echo: false
#| eval: false
write_rds(model1_rt_invGauss, file = "../models/model1_rt_invGauss.rds")
```

```{r}
#| echo: false
model1_rt_invGauss <- read_rds("../models/model1_rt_invGauss.rds")
```

```{r}
plot(posterior_predictive_check(model1_rt_invGauss))
```

```{r}
model2_rt_invGauss <- glmer(Reaction_time ~ Ethnicity_e * identity_e + (1 | id),
                            data = data_clean,
                            family = inverse.gaussian(link = "identity"),
                            control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5)))

model_parameters(model2_rt_invGauss)
```

```{r}
#| echo: false
#| eval: false
write_rds(model2_rt_invGauss, file = "../models/model2_rt_invGauss.rds")
```

```{r}
#| echo: false
model2_rt_invGauss <- read_rds("../models/model2_rt_invGauss.rds")
```

```{r}
plot(posterior_predictive_check(model2_rt_invGauss))
```

#### Model comparison - fixed effects

```{r}
anova(model0_rt_invGauss, model1_rt_invGauss)
```

```{r}
anova(model1_rt_invGauss, model2_rt_invGauss)
```

```{r}
model_parameters(model2_rt_invGauss) |> insight::print_html()
```

Model without interaction is better.

##### Adding random effects

```{r}
#| eval: false
model1.1_rt <- glmer(Reaction_time ~ Ethnicity_e + identity_e + (1 + identity_e | id),
                     data = data_clean,
                     family = inverse.gaussian(link = "identity"))
```

```{r}
#| echo: false
#| eval: false
write_rds(model1.1_rt, file = "../models/model1.1_rt_invGauss.rds")
```

```{r}
#| echo: false
model1.1_rt <- read_rds("../models/model1.1_rt_invGauss.rds")
```

```{r}
model_parameters(model1.1_rt)
```

```{r}
anova(model1_rt_invGauss, model1.1_rt)
```

```{r}
#| eval: false
model1.2_rt <- glmer(Reaction_time ~ Ethnicity_e + identity_e + (1 + Ethnicity_e + identity_e | id),
                     data = data_clean,
                     family = inverse.gaussian(link = "identity"),
                     control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5)))
```

```{r}
#| echo: false
#| eval: false
write_rds(model1.2_rt, file = "../models/model1.2_rt_invGauss.rds")
```

```{r}
#| echo: false
model1.2_rt <- read_rds("../models/model1.2_rt_invGauss.rds")
```

```{r}
model_parameters(model1.2_rt)
```

```{r}
anova(model1.1_rt, model1.2_rt)
```

Model with random intercepts + random slopes for IDENTITY only is best.

#### Starting with maximal model

This model did not converge with, or without correlations between random effects. It has also did not converge when random slopes for `Ethnicity`, `identity` and their interaction were removed.

```{r}
#| eval: false
model_maximal_rt <- glmer(Reaction_time ~ Ethnicity_e * identity_e + (1 + Ethnicity_e * identity_e | id) + (0 + dummy(Ethnicity, "ARAB") + dummy(Ethnicity, "ARAB"):identity || Name) + (0 + dummy(Ethnicity, "JEWISH") + dummy(Ethnicity, "JEWISH"):identity || Name),
                          data = data_clean,
                          family = inverse.gaussian(link = "identity"),
                          control = glmerControl(optimizer = "Nelder_Mead", optCtrl = list(maxfun = 2e9)))
```

Therefore, proceeding without them:

```{r}
#| eval: false
model_maximal_rt <- glmer(Reaction_time ~ Ethnicity_e * identity_e + (1 + Ethnicity_e * identity_e | id),
                          data = data_clean,
                          family = inverse.gaussian(link = "identity"),
                          control = glmerControl(optimizer = "Nelder_Mead", optCtrl = list(maxfun = 2e9)))
```

This model too failed to converge.

```{r}
#| echo: false
#| eval: false
write_rds(model_maximal_rt, file = "../models/model_maximal_rt_invGauss.rds")
```

```{r}
#| echo: false
model_maximal_rt <- read_rds("../models/model_maximal_rt_invGauss.rds")
```

No random slope for Ethnicity.

```{r}
#| eval: false
model3_rt <- glmer(Reaction_time ~ Ethnicity_e * identity_e + (1 + identity_e + Ethnicity_e:identity_e | id),
                   data = data_clean,
                   family = inverse.gaussian(link = "identity"),
                   control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e9)))
```

```{r}
#| echo: false
#| eval: false
write_rds(model3_rt, file = "../models/model3_rt_invGauss.rds")
```

```{r}
#| echo: false
model3_rt <- read_rds("../models/model3_rt_invGauss.rds")
```

```{r}
model_parameters(model3_rt)
```

#### Gradual addition of random effects

##### Empty model

```{r}
#| eval: false
model2_rt <- glmer(Reaction_time ~ Ethnicity_e * identity_e + (1 | id),
                   data = data_clean,
                   family = inverse.gaussian(link = "identity"),
                   control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e9)))
```

```{r}
#| echo: false
#| eval: false
write_rds(model2_rt, file = "../models/model2_rt_invGauss.rds")
```

```{r}
#| echo: false
model2_rt <- read_rds("../models/model2_rt_invGauss.rds")
```

```{r}
model_parameters(model2_rt)
```

##### random slope for identity

```{r}
#| eval: false
model2.1_rt <- glmer(Reaction_time ~ Ethnicity_e * identity_e + (1 + identity_e | id),
                     data = data_clean,
                     family = inverse.gaussian(link = "identity"),
                     control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e9)))
```

```{r}
#| echo: false
#| eval: false
write_rds(model2.1_rt, file = "../models/model2.1_rt_invGauss.rds")
```

```{r}
#| echo: false
model2.1_rt <- read_rds("../models/model2.1_rt_invGauss.rds")
```

```{r}
model_parameters(model2.1_rt)
```

##### random slopes for identity and social status

```{r}
#| eval: false
model2.2_rt <- glmer(Reaction_time ~ Ethnicity_e * identity_e + (1 + Ethnicity_e + identity_e | id),
                     data = data_clean,
                     family = inverse.gaussian(link = "identity"),
                     control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e9)))
```

```{r}
#| echo: false
#| eval: false
write_rds(model2.2_rt, file = "../models/model2.2_rt_invGauss.rds")
```

```{r}
#| echo: false
model2.2_rt <- read_rds("../models/model2.2_rt_invGauss.rds")
```

```{r}
model_parameters(model2.2_rt)
```

```{r}
sjPlot::tab_model(model2.2_rt, show.icc = F, show.r2 = F)

lme4::ranef(model2.2_rt)
```

#### Model comparison

```{r}
anova(model3_rt, model2_rt)
```

```{r}
anova(model3_rt, model2.1_rt)
```

```{r}
anova(model3_rt, model2.2_rt)
```

## Maximal model - log-normal

```{r}
#| eval: false
model_maximal_rt_log <- lmer(log(Reaction_time) ~ Ethnicity_e * identity_e + (1 + Ethnicity_e * identity_e | id),
                              data = data_clean,
                              control = lmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5)))
```

```{r}
#| echo: false
#| eval: false
write_rds(model_maximal_rt_log, file = "../models/model_maximal_log_rt_invGauss.rds")
```

```{r}
#| echo: false
model_maximal_rt_log <- read_rds("../models/model_maximal_log_rt_invGauss.rds")
```

```{r}
model_parameters(model_maximal_rt_log, exponentiate = T)
```

## Inspecting the interaction

```{r}
(ems <- emmeans(model2.2_rt, ~ Ethnicity_e * identity_e, type = "response"))
```

```{r}
contrast(ems, method = "revpairwise", by = "identity_e")
```

```{r}
contrast(ems, list(repetition = c(0.5,0.5,-0.5,-0.5),
                   Ethnicity = c(-0.5,0.5,-0.5,0.5)))
```

Contrast in DIFF (identity_e = 1) is not significant (and not in the right direction).

## Visualizations

```{r}
#| code-fold: true
#| code-summary: "ggplot code"
plot1_rt <- data_clean |>
  mutate(Identity = factor(Identity, levels = c("Same", "Diff"))) |>
  ggplot(aes(x = Identity, y = Reaction_time, color = Ethnicity, group = Ethnicity)) +
  geom_smooth(aes(x = Identity, y = Reaction_time, group = Participant_Private_ID), color = "grey84", method = "lm", se = F, inherit.aes = F) +
  geom_smooth(method = "lm", se = F) +
  scale_x_discrete(labels = c("Same", "Different")) +
  facet_wrap(~ Ethnicity, scales = "free") +
  scale_y_continuous(limits = c(180, 900), labels = seq(200, 900, 100), breaks = seq(200, 900, 100)) +
  scale_color_manual(values = c("#4b3d8f", "#4b3d8f")) +
  guides(color = "none") +
  labs(y = "Reaction time (ms)", x = "Face repetition condition", title = "Mean RT in each face repetition and social status condition") +
  theme_bw() +
  theme(panel.border = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.line = element_line(colour = "black"),
        axis.title = element_text(family = "serif", size = 12),
        plot.title = element_text(family = "serif", size = 14, hjust = 0.5))

plot1_rt
```

```{r}
ggsave("../plots/glmer_plot_rt.png", plot = plot1_rt, width = 2450, height = 2100, units = "px")
```

Since I didn't model the shape parameter ($\lambda$), it is kept constant.

```{r}
#| code-fold: true
#| code-summary: "ggplot code"
library(distributional)
library(actuar)
library(patchwork)

coefficients <- model_parameters(model_maximal_rt) |> data.frame()

b_intercept <- coefficients$Coefficient[1]
b_EthnicityARAB <- coefficients$Coefficient[2]
b_identityDiff <- coefficients$Coefficient[3]
b_EthnicityARABxidentityDiff <- coefficients$Coefficient[4]

plot_ARAB_status <- ggplot(data = data.frame("dummy" = seq(1:10)), aes(xdist = distributional::dist_inverse_gaussian(mean = b_intercept + b_EthnicityARAB, shape = 34657.7), color = "Same")) +
  stat_slab(fill = NA) +
  stat_slab(aes(xdist = distributional::dist_inverse_gaussian(mean = b_intercept + b_EthnicityARAB + b_identityDiff + b_EthnicityARABxidentityDiff, shape = 34657.7), color = "Different"), fill = NA) + 
  scale_x_continuous(limits = c(300, 900), breaks = seq(0, 900, 100), labels = seq(0, 900, 100)) +
  scale_colour_manual(values = c("#4b3d8f", "#37a987")) + 
  theme_classic() +
  labs(x = "Reaction Time (ms)", title = "ARAB Status", colour = "Face repetition condition") +
  theme(axis.title.y = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        plot.title = element_text(family = "serif", size = 15, hjust = 0.5))

plot_JEWISH_status <- ggplot(data = data.frame("dummy" = seq(1:10)), aes(xdist = distributional::dist_inverse_gaussian(mean = b_intercept, shape = 34657.7), color = "Same")) +
  stat_slab(fill = NA) +
  stat_slab(aes(xdist = distributional::dist_inverse_gaussian(mean = b_intercept + b_identityDiff, shape = 34657.7), color = "Different"), fill = NA) + 
  scale_x_continuous(limits = c(300, 900), breaks = seq(0, 900, 100), labels = seq(0, 900, 100)) +
  scale_colour_manual(values = c("#4b3d8f", "#37a987")) + 
  theme_classic() +
  labs(x = "Reaction Time (ms)", title = "JEWISH Status", colour = "Face repetition condition") +
  theme(axis.title.y = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        plot.title = element_text(family = "serif", size = 15, hjust = 0.5))

dist_plot <- (plot_ARAB_status + plot_JEWISH_status) +
  plot_layout(guides = "collect") +
  plot_annotation(title = "Predicted distribution of RT",
                  subtitle = "RT for Different faces is consistently larger",
                  theme = theme(plot.title = element_text(size = 20, family = "serif", hjust = 0.5),
                                plot.subtitle = element_text(size = 12, family = "serif", hjust = 0.5)))

dist_plot
```

```{r}
#| eval: false
#| echo: false
ggsave("../plots/dist_plot_rt.png", plot = dist_plot, width = 2450, height = 2100, units = "px")
```

# Correct answers

I deviate from the pre-registration again here, and fit the binomial models with the *probit*, instead of *logit* link function. This has little to no influence on model estimation or fit, only makes it easier for me to interpret.

## Tidying

```{r}
data_clean_ca <- data |>
  mutate(Name = factor(Name),
         Ethnicity = factor(Ethnicity, levels = c("JEWISH", "ARAB")),
         identity = factor(Identity, levels = c("Same", "Diff")),
         identity_response = factor(Identity_answer, levels = c("Same", "Diff")),
         target_sex = factor(target_sex, levels = c("male", "female")),
         id = factor(Participant_Public_ID)) |>
  group_by(id) |>
  mutate(Ethnicity_e = case_when(Ethnicity == "ARAB" ~ 1,
                                     Ethnicity == "JEWISH" ~ -1),
         identity_e = case_when(identity == "Diff" ~ 1,
                                identity == "Same" ~ -1),
         target_sex_e = case_when(target_sex == "male" ~ 1,
                                  target_sex == "female" ~ -1)) |>
  mutate(trial = row_number(id)) |>
  ungroup() |>
  select(id, trial, target_sex, target_sex_e, Ethnicity, Ethnicity_e, Name, identity, identity_e, identity_response, Reaction_time)
```

## Descriptives

```{r}
#| code-fold: true
#| code-summary: "ggplot code"
plot_responses <- data_clean_ca |>
  ggplot(aes(x = identity, fill = identity_response)) +
  geom_bar(position = "dodge", stat = "count") +
  facet_wrap(~Ethnicity) +
  scale_fill_manual(values = color_vec) +
  labs(x = "Second Face", fill = "Second Face Response") +
  scale_y_continuous(breaks = seq(0, 2500, 200), labels = seq(0, 2500, 200)) +
  theme_classic()

plot_responses
```

## Model 0

```{r}
#| eval: false
#| echo: false
ordinal_model0_ca <- ordinal::clmm(identity_response ~ 1 + (1 | id),
                                   data = data_clean_ca,
                                   link = "probit",
                                   threshold = "flexible",
                                   Hess = TRUE)
```

```{r}
#| echo: false
#| eval: false
write_rds(ordinal_model0_ca, file = "../models/ordinal_model0_ca.rds")
```

```{r}
#| echo: false
ordinal_model0_ca <- read_rds("../models/ordinal_model0_ca.rds")
```

```{r}
#| eval: false
#| echo: false
model_parameters(ordinal_model0_ca)
```

```{r}
#| eval: false
model0_ca <- glmer(identity_response ~ 1 + (1 | id),
                   data = data_clean_ca,
                   family = binomial(link = "logit"))
```

```{r}
#| echo: false
#| eval: false
write_rds(model0_ca, file = "../models/model0_ca.rds")
```

```{r}
#| echo: false
model0_ca <- read_rds("../models/model0_ca.rds")
```

```{r}
model_parameters(model0_ca, exponentiate = T)
```

## Model 0.5

```{r}
#| eval: false
#| echo: false
ordinal_model0.5_ca <- ordinal::clmm(identity_response ~ identity + (1 | id),
                                   data = data_clean_ca,
                                   link = "probit",
                                   threshold = "flexible",
                                   Hess = TRUE)
```

```{r}
#| echo: false
#| eval: false
write_rds(ordinal_model0.5_ca, file = "../models/ordinal_model0.5_ca.rds")
```

```{r}
#| echo: false
ordinal_model0.5_ca <- read_rds("../models/ordinal_model0.5_ca.rds")
```

```{r}
#| eval: false
#| echo: false
model_parameters(ordinal_model0.5_ca)
```

```{r}
#| eval: false
model0.5_ca <- glmer(identity_response ~ identity_e + (1 | id),
                     data = data_clean_ca,
                     family = binomial(link = "logit"))
```

```{r}
#| echo: false
#| eval: false
write_rds(model0.5_ca, file = "../models/model0.5_ca.rds")
```

```{r}
#| echo: false
model0.5_ca <- read_rds("../models/model0.5_ca.rds")
```

```{r}
model_parameters(model0.5_ca, exponentiate = T)
```

## Model 1

```{r}
#| eval: false
#| echo: false
ordinal_model1_ca <- ordinal::clmm(identity_response ~ identity + Ethnicity + (1 | id),
                                   data = data_clean_ca,
                                   link = "probit",
                                   threshold = "flexible",
                                   Hess = TRUE)
```

```{r}
#| echo: false
#| eval: false
write_rds(ordinal_model1_ca, file = "../models/ordinal_model1_ca.rds")
```

```{r}
#| echo: false
ordinal_model1_ca <- read_rds("../models/ordinal_model1_ca.rds")
```

```{r}
#| eval: false
#| echo: false
model_parameters(ordinal_model1_ca)
```

```{r}
#| eval: false
model1_ca <- glmer(identity_response ~ identity_e + Ethnicity_e + (1 | id),
                     data = data_clean_ca,
                     family = binomial(link = "logit"))
```

```{r}
#| echo: false
#| eval: false
write_rds(model1_ca, file = "../models/model1_ca.rds")
```

```{r}
#| echo: false
model1_ca <- read_rds("../models/model1_ca.rds")
```

```{r}
model_parameters(model1_ca, exponentiate = T)
```

## Model 2

```{r}
#| eval: false
#| echo: false
ordinal_model2_ca <- ordinal::clmm(identity_response ~ identity * Ethnicity + (1 | id),
                                   data = data_clean_ca,
                                   link = "probit",
                                   threshold = "flexible",
                                   Hess = TRUE)
```

```{r}
#| echo: false
#| eval: false
write_rds(ordinal_model2_ca, file = "../models/ordinal_model2_ca.rds")
```

```{r}
#| echo: false
ordinal_model2_ca <- read_rds("../models/ordinal_model2_ca.rds")
```

```{r}
#| eval: false
#| echo: false
model_parameters(ordinal_model2_ca)
```

```{r}
#| eval: false
model2_ca <- glmer(identity_response ~ identity_e * Ethnicity_e + (1 | id),
                     data = data_clean_ca,
                     family = binomial(link = "logit"))
```

```{r}
#| echo: false
#| eval: false
write_rds(model2_ca, file = "../models/model2_ca.rds")
```

```{r}
#| echo: false
model2_ca <- read_rds("../models/model2_ca.rds")
```

```{r}
model_parameters(model2_ca, exponentiate = T)
```

### Model comparison - fixed effects

```{r}
anova(model0_ca, model1_ca)
```

```{r}
anova(model1_ca, model2_ca)
```

## Random effects

### Model 2.1

```{r}
#| eval: false
#| echo: false
ordinal_model2.1_ca <- ordinal::clmm(identity_response ~ identity * Ethnicity + (1 + identity | id),
                                   data = data_clean_ca,
                                   link = "probit",
                                   threshold = "flexible",
                                   Hess = TRUE)
```

```{r}
#| echo: false
#| eval: false
write_rds(ordinal_model2.1_ca, file = "../models/ordinal_model2.1_ca.rds")
```

```{r}
#| echo: false
ordinal_model2.1_ca <- read_rds("../models/ordinal_model2.1_ca.rds")
```

```{r}
#| eval: false
#| echo: false
model_parameters(ordinal_model2.1_ca)
```

```{r}
#| eval: false
model2.1_ca <- glmer(identity_response ~ Ethnicity_e * identity_e + (1 + identity_e | id),
                     data = data_clean_ca,
                     family = binomial(link = "logit"),
                     control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5)))
```

```{r}
#| echo: false
#| eval: false
write_rds(model2.1_ca, file = "../models/model2.1_ca.rds")
```

```{r}
#| echo: false
model2.1_ca <- read_rds("../models/model2.1_ca.rds")
```

```{r}
model_parameters(model2.1_ca, exponentiate = T)
```

```{r}
ems <- emmeans(model2.1_ca, ~ Ethnicity_e * identity_e, type = "response")

contrast(ems, method = list(repetition = c(0.5,0.5,-0.5,-0.5),
                            Ethnicity = c(-0.5,0.5,-0.5,0.5)))
```

```{r}
contrast(ems, method = "revpairwise", by = "identity_e")
```

```{r}
sjPlot::tab_model(model2.1_ca, transform = "exp")
```

### Model 2.2

```{r}
#| eval: false
#| echo: false
ordinal_model2.2_ca <- ordinal::clmm(identity_response ~ identity * Ethnicity + (1 + identity + Ethnicity | id),
                                   data = data_clean_ca,
                                   link = "probit",
                                   threshold = "flexible",
                                   Hess = TRUE)
```

```{r}
#| echo: false
#| eval: false
write_rds(ordinal_model2.2_ca, file = "../models/ordinal_model2.2_ca.rds")
```

```{r}
#| echo: false
ordinal_model2.2_ca <- read_rds("../models/ordinal_model2.2_ca.rds")
```

```{r}
#| eval: false
#| echo: false
model_parameters(ordinal_model2.1_ca)
```

```{r}
#| eval: false
model2.2_ca <- glmer(identity_response ~ identity_e * Ethnicity_e + (1 + identity_e + Ethnicity_e | id),
                     data = data_clean_ca,
                     family = binomial(link = "logit"),
                     control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5)))
```

```{r}
#| echo: false
#| eval: false
write_rds(model2.2_ca, file = "../models/model2.2_ca.rds")
```

```{r}
#| echo: false
model2.2_ca <- read_rds("../models/model2.2_ca.rds")
```

```{r}
model_parameters(model2.2_ca, exponentiate = T)
```

### Maximal model

```{r}
#| eval: false
model_maximal_ca <- glmer(identity_response ~ identity_e * Ethnicity_e + (1 + identity_e * Ethnicity_e | id),
                     data = data_clean_ca,
                     family = binomial(link = "logit"),
                     control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5)))
```

```{r}
#| echo: false
#| eval: false
write_rds(model_maximal_ca, file = "../models/model_maximal_ca.rds")
```

```{r}
#| echo: false
model_maximal_ca <- read_rds("../models/model_maximal_ca.rds")
```

```{r}
model_parameters(model_maximal_ca, exponentiate = T)
```

## Model comparison - random effects

```{r}
anova(model2_ca, model2.1_ca)
```

```{r}
anova(model2.1_ca, model2.2_ca)
```

```{r}
anova(model2.1_ca, model_maximal_ca)
```

## Visualizations

```{r}
#| code-fold: true
#| code-summary: "ggplot helper function"
distributions_plot_2_vars <- function(model, pallete = 9, ttl = "") {
  
  library(ggplot2)
  library(patchwork)
  
  Threshold <- coef(model)[1]
  b_identityDiff <- coef(model)["identityDiff"]
  b_EthnicityARAB <- coef(model)["EthnicityARAB"]
  b_interaction <- coef(model)["identityDiff:EthnicityARAB"]
  
  dist_plot_pre <- ggplot() +
    
    # JEWISH + Same
    stat_function(aes(linetype = "Same"), fun = dnorm,
                  args = list(mean = 0, sd = 1),
                  linewidth = 1) + 
    # JEWISH + Different
    stat_function(aes(linetype = "Different"), fun = dnorm, 
                  args = list(mean = b_identityDiff, sd = 1),
                  linewidth = 1) + 
    # Thresholds
    geom_vline(aes(xintercept = Threshold, color = ""),
               linewidth = 1.5) + 
    scale_color_manual(values = color_vec[1], labels = "Criterion") + 
    labs(y = NULL, linetype = "Second Face", x = "SD", title = "JEWISH Social Status", color = NULL) + 
    expand_limits(x = c(-3, 6), y = 0.45) +
    scale_x_continuous(breaks = seq(-3, 6, 1), labels = seq(-3, 6, 1)) +
    theme_classic() +
    theme(plot.title = element_text(size = 15, family = "serif", hjust = 0.5),
          axis.text.y = element_blank(),
          axis.ticks.y = element_blank())
  
  dist_plot_post <- ggplot() +
    
    # ARAB + Same
    stat_function(aes(linetype = "Same"), fun = dnorm,
                  args = list(mean = 0, sd = 1),
                  linewidth = 1) + 
    # ARAB + Different
    stat_function(aes(linetype = "Different"), fun = dnorm, 
                  args = list(mean = b_identityDiff + b_interaction, sd = 1),
                  linewidth = 1) + 
    # Thresholds
    geom_vline(aes(xintercept = Threshold - b_EthnicityARAB, color = ""),
               linewidth = 1.5) + 
    scale_color_manual(values = color_vec[1], labels = "Criterion") + 
    labs(y = NULL, linetype = "Second Face", x = "SD", title = "ARAB Social Status", color = NULL) + 
    expand_limits(x = c(-3, 6), y = 0.45) + 
    scale_x_continuous(breaks = seq(-3, 6, 1), labels = seq(-3, 6, 1)) +
    theme_classic() +
    theme(plot.title = element_text(size = 15, family = "serif", hjust = 0.5),
          axis.text.y = element_blank(),
          axis.ticks.y = element_blank())
  
  dist_plot <- (dist_plot_pre / dist_plot_post) +
    plot_layout(guides = "collect") +
    plot_annotation(title = ttl,
                    subtitle = "Different faces are recognized better then identical faces, with no significant interaction with social status",
                    theme = theme(plot.title = element_text(family = "serif", size = 20, hjust = .5),
                                  plot.subtitle = element_text(family = "serif", size = 12, hjust = .5)))
  
  return(dist_plot)
}
```

```{r}
(dist_plot_answers <- distributions_plot_2_vars(ordinal_model2.1_ca, ttl = "Signal Detection Perspective"))
```

```{r}
#| eval: false
#| echo: false
ggsave(filename = "../plots/SDT_plot_correct_identification.png", plot = dist_plot_answers, width = 2450, height = 1446, units = "px")
```

# Bayesian analysis - Robustness check

Fitting the models again with Posterior sampling.

```{r}
library(brms)
library(tidybayes)
library(posterior)
```

```{r}
#| echo: false
cmdstanr::set_cmdstan_path(path = "C:/Users/tomer/AppData/Local/R/win-library/4.2/cmdstan-2.32.1")
```

## Reaction time

### Formula

I deviate from the pre-registration here and fit a log-normal model for Reaction time. The reason being the difficulty of the Bayesian inverse gaussian model to converge, even with 64k MCMC iteration it only yielded $ECC < 50$ for fixed effects coefficients.

```{r}
#| eval: false
rt_formula <- bf(log(Reaction_time) ~ Ethnicity * identity + (1 + Ethnicity * identity | id),
                 sigma ~ 1 + Ethnicity * identity) # modeling sigma for robustness check)
```

### Prior elicitation

Prior means are equal to the coefficients found by Reggev et al., [-@reggev_human_2020], with medium size variance.

```{r}
#| eval: false
rt_prior <- set_prior("normal(6.03, 1)", class = "Intercept") +
  set_prior("normal(0.01, 1)", coef = "EthnicityARAB") +
  set_prior("normal(0.1, 1)", coef = "identityDiff") +
  set_prior("normal(-0.04, 1)", coef = "identityDiff:EthnicityARAB") +
  set_prior("exponential(1)", class = "sd") # sd of random effects
```

### Model

```{r}
#| eval: false
rt_b_model <- brm(formula = rt_formula,
                  data = data_clean,
                  family = gaussian(),
                  iter = 8000,
                  chains = 4,
                  init = 0,
                  cores = 4,
                  backend = "cmdstanr",
                  seed = 14)
```

```{r}
#| eval: false
#| echo: false
write_rds(rt_b_model, file = "../models/reaction_time_bayes_model_maximal.rds")
```

```{r}
#| echo: false
rt_b_model <- read_rds("../models/reaction_time_bayes_model_maximal.rds")
```

```{r}
model_parameters(rt_b_model, exponentiate = T, centrality = "all") |> insight::print_html()
```

### Visualization - Posterior Predictive Distributions

```{r}
#| echo: false
#| eval: false
chains <- spread_draws(rt_b_model, b_Intercept, b_EthnicityARAB, b_identityDiff, !!sym("b_EthnicityARAB:identityDiff"), b_sigma_Intercept, b_sigma_EthnicityARAB, b_sigma_identityDiff, !!sym("b_sigma_EthnicityARAB:identityDiff")) |>
  mutate(across(!c(.chain, .iteration, .draw), exp)) |>
  mutate(mu_JEWISH_same = b_Intercept,
         sd_JEWISH_same = sqrt(b_sigma_Intercept),
         mu_JEWISH_diff = b_Intercept * b_identityDiff,
         sd_JEWISH_diff = sqrt(b_sigma_Intercept * b_sigma_identityDiff),
         mu_ARAB_same = b_Intercept * b_EthnicityARAB,
         sd_ARAB_same = sqrt(b_sigma_Intercept * b_sigma_EthnicityARAB),
         mu_ARAB_diff = b_Intercept * b_identityDiff * b_EthnicityARAB * !!sym("b_EthnicityARAB:identityDiff"),
         sd_ARAB_diff = sqrt(b_sigma_Intercept * b_sigma_identityDiff * b_sigma_EthnicityARAB * !!sym("b_sigma_EthnicityARAB:identityDiff")))
```

```{r}
#| eval: false
#| code-fold: true
#| code-summary: "setting up data for plot"
new_data <- expand_grid(id = unique(data_clean$Participant_Public_ID),
                        identity = unique(data_clean$identity),
                        Ethnicity = unique(data_clean$Ethnicity))

pp <- posterior_predict(rt_b_model, newdata = new_data) |>
  data.frame()

pp_t <- new_data |>
  cbind(data.frame(t(pp))) |>
  mutate(across(!c(id, identity, Ethnicity), exp))

names(pp_t) <- c("id", "identity", "Ethnicity", paste0("draw", c(1:16000), sep = ""))

pp_t <- pp_t |>
  select(-id) |>
  pivot_longer(cols = !c(identity, Ethnicity),
               names_to = ".draw",
               values_to = ".value")
```

```{r}
#| eval: false
#| code-fold: true
#| code-summary: "ggplot code"
rt_b_plot <- pp_t |>
  #group_by(identity, Ethnicity) |>
  #slice_sample(prop = 0.01) |> # used to speed plotting
  ggplot(aes(y = .value, x = identity, color = Ethnicity, fill = Ethnicity)) +
    stat_halfeye(aes(alpha = 1), position = position_dodge(0.2), slab_color = "gray49") +
    scale_fill_manual(values = color_vec, labels = c("JEWISH", "ARAB")) +
    scale_color_manual(values = color_vec) +
    scale_y_continuous(limits = c(200, 1000), breaks = seq(200, 1000, 100), labels = seq(200, 1000, 100)) +
    scale_x_discrete(labels = c("Same", "Different")) +
    theme_classic() +
    guides(alpha = "none", color = "none") +
    labs(x = "Second Face", y = "Reaction Time (ms)", title = "Posterior Predictive Distributions of Reaction Times", subtitle = "Shorter predicted reaction times for 'same' faces, no evidence for an interaction with Social Status", alpha = NULL, fill = "Social Status") +
    theme(plot.title = element_text(size = 20, family = "serif", hjust = 0.5),
          plot.subtitle = element_text(size = 12, family = "serif", hjust = 0.5),
          axis.title = element_text(size = 13, family = "serif"),
          legend.title = element_text(size = 13, family = "serif", hjust = 0.5))

rt_b_plot
```

![](../plots/bayes_dist_plot_rt.png){fig-align="center"}

```{r}
#| eval: false
#| echo: false
ggsave("../plots/bayes_dist_plot_rt.png", plot = rt_b_plot, width = 2450, height = 2100, units = "px")
```

### Visualization - Linear predictor

```{r}
#| echo: false
set.seed(14)
```

```{r}
#| code-fold: true
#| code-summary: "setting up data for plot"
new_data_rt <- expand_grid(id = sample(data_clean$Participant_Public_ID, 10),
                           identity = unique(data_clean$identity),
                           Ethnicity = unique(data_clean$Ethnicity))

rt_pred <- new_data_rt |>
  add_linpred_draws(rt_b_model, ndraws = 100, seed = 14) |>
  mutate(.linpred = exp(.linpred),
         identity = factor(case_when(identity == "Diff" ~ "Different",
                              .default = "Same"), levels = c("Same", "Different")),
         Ethnicity = factor(case_when(Ethnicity == "ARAB" ~ "ARAB",
                                   .default = "JEWISH"), levels = c("JEWISH", "ARAB")))

rt_pred_grand_means <- rt_pred |>
  group_by(identity, Ethnicity) |>
  reframe(grand_mean = mean(.linpred))
```

```{r}
#| code-fold: true
#| code-summary: "ggplot code"
rt_line_plot <- rt_pred |>
  mutate(id = factor(id)) |>
  ggplot(aes(x = identity, y = .linpred, color = id, group = interaction(id, .draw))) +
  geom_line(alpha = 0.8) +
  scale_color_brewer(type = "div", palette = 9) +
  geom_point(data = rt_pred_grand_means, aes(x = identity, y = grand_mean),
             size = 2,
             inherit.aes = F) +
  geom_line(data = rt_pred_grand_means, aes(x = identity, y = grand_mean, group = Ethnicity),
             linewidth = 1,
             inherit.aes = F) +
  scale_y_continuous(limits = c(350, 750), breaks = seq(350, 750, 50), labels = seq(350, 750, 50)) +
  facet_wrap(~Ethnicity) +
  guides(color = "none") +
  labs(x = "Second Face", y = "Reaction Time (ms)", title = "Posterior conditional means of RT for 10 random participants", subtitle = "Participants differ by lines color, great variance in intercepts and slopes for face condition can be seen", color = NULL) +
  theme_classic() +
  theme(plot.title = element_text(size = 19, family = "serif", hjust = 0.5),
        plot.subtitle = element_text(size = 11, family = "serif", hjust = 0.5),
        axis.title = element_text(size = 12, family = "serif"))

rt_line_plot
```

```{r}
#| eval: false
#| echo: false
ggsave("../plots/bayes_spaghetti_plot_rt.png", plot = rt_line_plot, width = 2450, height = 2100, units = "px")
```

## Correct answers

### Formula

```{r}
#| eval: false
ca_formula_0 <- bf(identity_response ~ 1 + (1 | id))

ca_formula_1 <- bf(identity_response ~ identity + Ethnicity + (1 | id))

ca_formula_2 <- bf(identity_response ~ identity * Ethnicity + (1 | id))

ca_formula_maximal <- bf(identity_response ~ identity * Ethnicity + (1 + identity * Ethnicity | id),
                         disc ~ 1 + identity * Ethnicity,
                         nl = TRUE)
```

### Prior elicitation

Based on Reggev et al., 2020 [-@reggev_human_2020]. Normal prior with means equal to the coefficients found previously. Prior will be defined only in the maximal model.

```{r}
#| eval: false
ca_prior <- set_prior("normal(-0.12, 1)", class = "Intercept") +
  set_prior("normal(0.13, 1)", coef = "EthnicityARAB") +
  set_prior("normal(0.02, 1)", coef = "identityDiff") +
  set_prior("normal(0.11, 1)", coef = "identityDiff:EthnicityARAB") +
  set_prior("exponential(1)", class = "sd") # sd of random effects
```

### Model

```{r}
#| eval: false
ca_b_model0 <- brm(formula = ca_formula_0,
                  data = data_clean_ca,
                  family = bernoulli(link = "probit"),
                  iter = 2000,
                  chains = 4,
                  init = 0,
                  cores = 4,
                  backend = "cmdstanr",
                  seed = 14)
```

```{r}
#| echo: false
#| eval: false
write_rds(ca_b_model0, file = "../models/correct_answers_bayes_model0.rds")
```

```{r}
#| echo: false
ca_b_model0 <- read_rds("../models/correct_answers_bayes_model0.rds")
```

```{r}
model_parameters(ca_b_model0, centrality = "all") |> insight::print_html()
```

```{r}
#| eval: false
ca_b_model1 <- update(ca_b_model0,
                      formula = ca_formula_1,
                      newdata = data_clean_ca)
```

```{r}
#| echo: false
#| eval: false
write_rds(ca_b_model1, file = "../models/correct_answers_bayes_model1.rds")
```

```{r}
#| echo: false
ca_b_model1 <- read_rds("../models/correct_answers_bayes_model1.rds")
```

```{r}
model_parameters(ca_b_model1, centrality = "all") |> insight::print_html()
```

```{r}
#| eval: false
ca_b_model2 <- update(ca_b_model1,
                      formula = ca_formula_2)
```

```{r}
#| echo: false
#| eval: false
write_rds(ca_b_model2, file = "../models/correct_answers_bayes_model2.rds")
```

```{r}
#| echo: false
ca_b_model2 <- read_rds("../models/correct_answers_bayes_model2.rds")
```

```{r}
model_parameters(ca_b_model2, centrality = "all") |> insight::print_html()
```

```{r}
#| eval: false
ca_b_model_maximal <- brm(formula = ca_formula_maximal,
                          data = data_clean_ca,
                          family = bernoulli(link = "probit"),
                          prior = ca_prior,
                          iter = 2000,
                          chains = 4,
                          init = 0,
                          cores = 4,
                          backend = "cmdstanr",
                          seed = 14)
```

```{r}
#| echo: false
#| eval: false
write_rds(ca_b_model_maximal, file = "../models/correct_answers_bayes_model_maximal.rds")
```

```{r}
#| echo: false
ca_b_model_maximal <- read_rds("../models/correct_answers_bayes_model_maximal.rds")
```

```{r}
model_parameters(ca_b_model_maximal, centrality = "all") |> insight::print_html()
```

### Visualization

```{r}
#| code-fold: true
#| code-summary: "extracting MCMC draws"
chains <- spread_draws(ca_b_model_maximal, b_Intercept, b_identityDiff, b_EthnicityARAB, !!sym("b_identityDiff:EthnicityARAB"))

chains_for_plot <- chains |>
  mutate(criterion_JEWISH = -b_Intercept,
         criterion_ARAB = -b_Intercept - b_EthnicityARAB,
         d_prime_JEWISH = b_identityDiff,
         d_prime_ARAB = b_identityDiff + !!sym("b_identityDiff:EthnicityARAB")) |>
  select(.draw, criterion_JEWISH, d_prime_JEWISH, criterion_ARAB, d_prime_ARAB)

sdt_params <- chains_for_plot |>
  select(-.draw) |>
  mutate_all(rvar)
sdt_params <- sdt_params[1,]
```

```{r}
#| code-fold: true
#| code-summary: "setting up data for plot"
signal_dist_JEWISH_same <- chains_for_plot |>
  group_by(.draw) |>
  reframe(
    x = seq(-4, 6, length=200),
    d = dnorm(x, mean = 0, sd = 1)
  ) |>
  ungroup() |>
  curve_interval(.along = x, .width = 0.9)

signal_dist_JEWISH_diff <- chains_for_plot |>
  group_by(.draw) |>
  reframe(
    x = seq(-4, 6, length=200),
    d = dnorm(x, mean = d_prime_JEWISH, sd = 1)
  ) |>
  ungroup() |>
  curve_interval(.along = x, .width = 0.9)

signal_dist_ARAB_same <- chains_for_plot |>
  group_by(.draw) |>
  reframe(
    x = seq(-4, 6, length=200),
    d = dnorm(x, mean = 0, sd = 1)
  ) |>
  ungroup() |>
  curve_interval(.along = x, .width = 0.9)

signal_dist_ARAB_diff <- chains_for_plot |>
  group_by(.draw) |>
  reframe(
    x = seq(-4, 6, length=200),
    d = dnorm(x, mean = d_prime_ARAB, sd = 1)
  ) |>
  ungroup() |>
  curve_interval(.along = x, .width = 0.9)
```

```{r}
#| code-fold: true
#| code-summary: "ggplot code"
plot_range <- c(-3, 6)

plot1 <- ggplot() +
    # Noise
    geom_ribbon(aes(x = x, ymin = .lower, ymax = .upper),
                data = signal_dist_JEWISH_same,
                fill = "grey", alpha = 0.4) +
    geom_line(aes(x, d, linetype = "Same"), data = signal_dist_JEWISH_same) +
    # Noise + Signal
    geom_ribbon(aes(x = x, ymin = .lower, ymax = .upper),
                data = signal_dist_JEWISH_diff,
                fill = "grey", alpha = 0.4) +
    geom_line(aes(x, d, linetype = "Different"), data = signal_dist_JEWISH_diff) +
  
    # Threshold
    stat_slab(aes(xdist = criterion_JEWISH), fill = color_vec[1],
              color = "gray", alpha = 0.6, key_glyph = "polygon",
              data = sdt_params) +

    # Theme and scales
    labs(color = NULL, linetype = "Second Face", fill = "Criterion", x = "", y = NULL, title = NULL, subtitle = "JEWISH Status") +
    scale_x_continuous(limits = plot_range, breaks = seq(plot_range[1], plot_range[2]), labels = seq(plot_range[1], plot_range[2])) +
    theme_classic() +
    theme(axis.text.y = element_blank(),
          axis.ticks.y = element_blank(),
          plot.subtitle = element_text(size = 15, family = "serif"))

plot2 <- ggplot() +
    # Noise
    geom_ribbon(aes(x = x, ymin = .lower, ymax = .upper),
                data = signal_dist_ARAB_same,
                fill = "grey", alpha = 0.4) +
    geom_line(aes(x, d, linetype = "Same"), data = signal_dist_JEWISH_same) +
    # Noise + Signal
    geom_ribbon(aes(x = x, ymin = .lower, ymax = .upper),
                data = signal_dist_ARAB_diff,
                fill = "grey", alpha = 0.4) +
    geom_line(aes(x, d, linetype = "Different"), data = signal_dist_JEWISH_diff) +
  
    # Threshold
    stat_slab(aes(xdist = criterion_ARAB), fill = color_vec[1],
              color = "gray", alpha = 0.6, key_glyph = "polygon",
              data = sdt_params) +

    # Theme and scales
    labs(color = NULL, linetype = "Second Face", fill = "Criterion", x = "", y = NULL, title = NULL, subtitle = "ARAB Status") +
    scale_x_continuous(limits = plot_range, breaks = seq(plot_range[1], plot_range[2]), labels = seq(plot_range[1], plot_range[2])) +
    theme_classic() +
    theme(axis.text.y = element_blank(),
          axis.ticks.y = element_blank(),
          plot.subtitle = element_text(size = 15, family = "serif"))


plot_all <- (plot1 / plot2) +
  plot_layout(guides = "collect") +
  plot_annotation(title = "Signal Detection Perspective",
                  subtitle = str_wrap("Signal and Noise distributions are nicely separated, with the criterion located in the ideal spot (halfway between the distributions)", width = 100),
                  theme = theme(plot.title = element_text(size = 20, family = "serif", hjust = 0.5),
                                plot.subtitle = element_text(size = 12, family = "serif", hjust = 0.5)))

plot_all
```

```{r}
#| eval: false
#| echo: false
ggsave("../plots/bayes_dist_plot_ca.png", plot = plot_all, width = 2450, height = 2100, units = "px")
```

# Environment

```{r}
sessionInfo()
```

# Exploratory Analysis

## Targets Threat- Exploratory

Uploading-

```{r}
treat_data <- read.csv("C:/Users/97252/Documents/GitHub/face_cater/Study 1/data/sim_threat.csv") |>
  select(Participant.Private.ID, Response.Type, Response, Display, Spreadsheet..image) |>
  filter(Response.Type == "response", Display == "task") |>
  select(-Response.Type, -Display) |>
  mutate(Participant.Private.ID = as.character(Participant.Private.ID))

data_clean_threat <- data_clean |>
  left_join(treat_data, by = c("Participant_Private_ID" = "Participant.Private.ID", "First_Image" = "Spreadsheet..image")) %>%
  rename(first_image_threat = Response) |>
  left_join(treat_data, by = c("Participant_Private_ID" = "Participant.Private.ID", "Second_Image" = "Spreadsheet..image")) %>%
  rename(second_image_threat = Response) |>
  mutate(
    first_image_threat = as.numeric(first_image_threat),
    second_image_threat = as.numeric(second_image_threat)
  ) |>
  mutate(mean_threat = (first_image_threat + second_image_threat) / 2)|>
  mutate(mean_threat_C = scale(mean_threat, center = TRUE, scale = FALSE)
  )

  
```

### Checking the influence of the precieved threat on both Dependent Varaiables,

```{r}

```

## Precieved Anxiety- Exploratory

```{r}

colnames_spaces_to_underscore <- function(data = NULL) {
  dat <- data
  names(dat) <- stringr::str_replace_all(names(dat), pattern = " ", replacement = "_")
  return(dat)
}


Anxiety_data0 <- read.csv("C:/Users/97252/Documents/GitHub/face_cater/Study 1/data/Anxiety_stimu.csv")

Anxiety_data <- Anxiety_data0 |>
  filter(Response.Type == "response", grepl("value", Key)) |>
  select(Participant.Private.ID, Task.Name, Question, Response) |>
  # Rename the column right after it is selected
  rename(Participant_Private_ID = Participant.Private.ID) |>
  mutate(
    Participant_Private_ID = as.character(Participant_Private_ID),  
    Response = as.numeric(as.character(Response)) 
  ) |>
  group_by(Participant_Private_ID) |>
  summarise(Total_Response = sum(Response, na.rm = TRUE), .groups = 'drop') 

# View the first few rows of the filtered data to check
filtered_data1 <- colnames_spaces_to_underscore(filtered_data1)

data_clean_Anxiety <- data_clean |>
  left_join(Anxiety_data, by = "Participant_Private_ID")|>
  mutate(Anxiety_C = scale(Total_Response, center = TRUE, scale = FALSE ))


```

## Thermometer & Dehumanization Exploratory-

```{r}
Thermometer_data0 <- read.csv("C:/Users/97252/Documents/GitHub/face_cater/Study 1/data/thermometer_stimu.csv") 


Thermometer_data <- Thermometer_data0 |>
   filter(grepl("^[0-9]+$", Participant.Private.ID)) |>
    select(
    Participant_Private_ID = Participant.Private.ID,
    Thermometer_Value = `Thermometer.object.4.Value`,
    Jews_Value = `jews.object.10.Value`,
    Arabs_Value = `arabs.object.11.Value`
  ) |>
   mutate(
    Participant_Private_ID = as.character(Participant_Private_ID),  
    Thermometer_Value = as.numeric(as.character(Thermometer_Value)),
    Jews_Value = as.numeric(as.character(Jews_Value)),
    Arabs_Value = as.numeric(as.character(Arabs_Value)))|>
  mutate(Dehumanization_Value = Jews_Value - Arabs_Value)


data_clean_Thermometer <- data_clean |>
  left_join(Thermometer_data, by = "Participant_Private_ID")|>
  select(-Jews_Value, -Arabs_Value)|>
  mutate(Dehumanization_Value_C = scale(Dehumanization_Value, center = TRUE, scale = FALSE ))|>
    mutate(Thermometer_Value_C = scale(Thermometer_Value, center = TRUE, scale = FALSE ))


```
